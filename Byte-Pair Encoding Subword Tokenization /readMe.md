Byte-Pair Encoding (BPE) Subword Tokenization

ğŸ“Œ Assignment: Programming Assignment 1 (AIN442 / BBM497)

This repository contains a Python implementation of a variation of the Byte-Pair Encoding (BPE) algorithm for subword tokenization. The implementation follows the specifications provided in Programming Assignment 1 for AIN442 Practicum in Natural Language Processing / BBM497 NLP Lab at Hacettepe University.

ğŸš€ Features

âœ… Token Learner

Learns subword tokens from a given corpus (string or file).

Implements maximum merge count to limit the number of merges.

Returns (Merges, Vocabulary, TokenizedCorpus).

Respects whitespace boundariesâ€”tokens from different words are not merged.

âœ… Token Segmenter

Uses the learned merge rules to tokenize new input text.

âœ… File Output Support

Can write results to an output file instead of returning them as output.

âš™ï¸ Usage

ğŸ”¹ Training the Token Learner

ğŸ“‚ Train using a text file

(Merges, Vocabulary, TokenizedCorpus) = bpeFN("hw01_tiny.txt", 10)

ğŸ’¾ Save the output to a file

bpeFNToFile("hw01_tiny.txt", 1000, "output.txt")

ğŸ”¹ Tokenizing Text

Once the BPE merges have been learned, you can tokenize new text using:

tokenizedStr = bpeTokenize("sos sus ses sel fes araba", Merges)

